{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Image Anomaly Detection Model with Amazon SageMaker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "print (role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Training data to S3\n",
    "First we need to upload our data to S3. For simplicity we read all the images into memory and create one giant Numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "if not os.path.isfile(\"UCSD_Anomaly_Dataset.tar.gz\"):\n",
    "  response = request.urlretrieve(\"http://www.svcl.ucsd.edu/projects/anomaly/UCSD_Anomaly_Dataset.tar.gz\", \"UCSD_Anomaly_Dataset.tar.gz\")\n",
    "  tar = tarfile.open(\"UCSD_Anomaly_Dataset.tar.gz\")\n",
    "  tar.extractall()\n",
    "  tar.close()\n",
    "\n",
    "files = sorted(glob.glob('UCSD_Anomaly_Dataset.v1p2/UCSDped1/Train/*/*'))\n",
    "a = np.zeros((int(len(files),1,100,100))\n",
    "\n",
    "for idx in range(0, len(files)):\n",
    "    im = Image.open(files[idx])\n",
    "    im = im.resize((100,100))\n",
    "    a[idx,0,:,:] = np.array(im, dtype=np.float32)/255.0\n",
    "\n",
    "np.save(\"input_data_sagemaker\", a)\n",
    "inputs = sagemaker_session.upload_data(path='input_data_sagemaker.npy', bucket='s3://MY_S3_BUCKET', key_prefix='data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Deploy the standard way\n",
    "You need to upload the training data to an S3 bucket: check the script ```upload_data.py``` how to upload data to S3.\n",
    "Once the data is uploaded you can define the MXNet Estimator, which takes as argument an entry point ```train.py```, the role, the training instance type, the path where data is located and another path where the code shall be uploaded. If you don't indicate these paths, SageMaker will use a default bucket. Next we have to define the Deep Learning framework we want to use and the hyperparameters.\n",
    "\n",
    "It can be useful for debugging purposes to define the instance type as local in the beginning. Then the SageMaker will execute your code in your local Notebook instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.mxnet import MXNet\n",
    "\n",
    "MY_S3_BUCKET = ''\n",
    "\n",
    "mxnet_estimator = MXNet('train.py',\n",
    "                        role=role,\n",
    "                        train_instance_type='local',#'ml.m5.xlarge',\n",
    "                        train_instance_count=1,\n",
    "                        output_path='s3://MY_S3_BUCKET',\n",
    "                        code_location='s3://MY_S3_BUCKET',\n",
    "                        framework_version='1.3.0', py_version='py2',\n",
    "                        hyperparameters={'batch_size': 16,\n",
    "                         'epochs': 10,\n",
    "                         'learning_rate': 0.0001,\n",
    "                         'wd': 0.0})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can call fit on our training data. Behind the scenes SageMaker spin up your EC2 instance indicated in ```train_instance_type``` (if not set to local). Once the instance is ready SageMaker will download a MXNet Docker container, and execute the function ```train()``` from ```train.py```, which creates and trains the model. After training the model is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mxnet_estimator.fit({'train': 's3://MY_S3_BUCKET/data/input_data.npy'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once our autoencoder model is trained we can deploy it. Here we define that the endpoint shall run on a ```m5.xlarge``` instance, which does not provide any GPUs. Inference won't run very fast, but this instance type is therefore cheaper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = mxnet_estimator.deploy(instance_type='ml.m5.xlarge', initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the endpoint is ready, we can send requests to it. SageMaker provides standard code for model inference. But often it is useful to customize these functions, for this reason ```train.py``` overwrites the default ```model_fn```. In the following example we send a numpy array filled with zeros to the endpoint. The endpoint will verify the user request, parse the input, then load the model and return the inference results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(glob.glob('UCSD_Anomaly_Dataset.v1p2/UCSDped1/Test/*/*'))\n",
    "\n",
    "im = Image.open(files[0])\n",
    "im = im.resize((100,100))\n",
    "test_image = np.array(im, dtype=np.float32)/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import numpy_deserializer, npy_serializer\n",
    "import numpy as np\n",
    "\n",
    "predictor.accept = 'application/x-npy'\n",
    "predictor.content_type = 'application/x-npy'\n",
    "predictor.deserializer =  numpy_deserializer\n",
    "predictor.serializer =  npy_serializer\n",
    "print(predictor.predict(a))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
