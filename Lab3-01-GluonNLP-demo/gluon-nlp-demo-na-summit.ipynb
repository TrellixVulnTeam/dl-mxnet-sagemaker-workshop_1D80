{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using Pre-trained Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Word Embedding - Numerical representation for language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*\"You shall know a word by the company it keeps.\"* - John Rupert Firth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Tezgüino** <- What does this word mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* A bottle of *Tezgüino* is on the table\n",
    "* *Tezgüino* makes you drunk\n",
    "* Everybody likes *Tezgüino*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How about now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Word2Vec\n",
    "\n",
    "FastText\n",
    "\n",
    "GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's see these in practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gluonnlp in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (0.8.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from gluonnlp) (1.14.5)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.2.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gluonnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from mxnet import gluon\n",
    "from mxnet import nd\n",
    "import gluonnlp as nlp\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "text = \" hello world \\n hello nice world \\n hi world \\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We need a tokenizer to process this string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def simple_tokenize(source_str, token_delim=' ', seq_delim='\\n'):\n",
    "    return filter(None, re.split(token_delim + '|' + seq_delim, source_str))\n",
    "counter = nlp.data.count_tokens(simple_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'hello': 2, 'world': 3, 'nice': 1, 'hi': 1})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "vocab = nlp.Vocab(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', '<bos>', '<eos>', 'world', 'hello', 'hi', 'nice']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.idx_to_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fasttext_simple = nlp.embedding.create('fasttext', source='wiki.simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vocab.set_embedding(fasttext_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
       "<NDArray 300 @cpu(0)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.embedding['beautiful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.39567   0.21454  -0.035389 -0.24299  -0.095645]\n",
       " [ 0.10444  -0.10858   0.27212   0.13299  -0.33165 ]]\n",
       "<NDArray 2x5 @cpu(0)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.embedding['hello', 'world'][:, :5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Application of Pre-trained Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "embedding = nlp.embedding.create('glove', source='glove.6B.50d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vocab = nlp.Vocab(nlp.data.Counter(embedding.idx_to_token))\n",
    "vocab.set_embedding(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400004"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.idx_to_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71424\n",
      "beautiful\n"
     ]
    }
   ],
   "source": [
    "print(vocab['beautiful'])\n",
    "print(vocab.idx_to_token[71424])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Word Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def cos_sim(x, y):\n",
    "    return nd.dot(x, y) / (nd.norm(x) * nd.norm(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def norm_vecs_by_row(x):\n",
    "    return x / nd.sqrt(nd.sum(x * x, axis=1)).reshape((-1,1))\n",
    "\n",
    "def get_knn(vocab, k, word):\n",
    "    word_vec = vocab.embedding[word].reshape((-1, 1))\n",
    "    vocab_vecs = norm_vecs_by_row(vocab.embedding.idx_to_vec)\n",
    "    dot_prod = nd.dot(vocab_vecs[4:], word_vec)\n",
    "    indices = nd.topk(dot_prod.squeeze(), k=k+1, ret_typ='indices')\n",
    "    indices = [int(i.asscalar())+4 for i in indices]\n",
    "    # Remove unknown and input tokens.\n",
    "    return vocab.to_tokens(indices[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['babies', 'boy', 'girl', 'newborn', 'pregnant']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_knn(vocab, 5, 'baby')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can verify the cosine similarity of vectors of 'baby' and 'babies'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[0.83871305]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(vocab.embedding['baby'], vocab.embedding['babies'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let us find the 5 most similar words of 'beautiful' from the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lovely', 'gorgeous', 'wonderful', 'charming', 'beauty']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_knn(vocab, 5, 'beautiful')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Word Analogy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def get_top_k_by_analogy(vocab, k, word1, word2, word3):\n",
    "    word_vecs = vocab.embedding[word1, word2, word3]\n",
    "    \n",
    "    word_diff = (word_vecs[1] - word_vecs[0] + word_vecs[2])\n",
    "    \n",
    "    vocab_vecs = norm_vecs_by_row(vocab.embedding.idx_to_vec)\n",
    "    dot_prod = nd.dot(vocab_vecs[4:], word_diff.squeeze()).squeeze()\n",
    "    \n",
    "    indices = dot_prod.topk(k=k, ret_typ='indices')\n",
    "    indices = [int(i.asscalar())+4 for i in indices]\n",
    "    return vocab.to_tokens(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['daughter']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_k_by_analogy(vocab, 1, 'man', 'woman', 'son')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anelka', 'ribery', 'zidane']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_k_by_analogy(vocab, 3, 'argentina', 'messi', 'france')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cricket']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_k_by_analogy(vocab, 1, 'argentina', 'football', 'india')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['quesadillas']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_k_by_analogy(vocab, 1, 'france', 'crepes', 'argentina')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Text Classification with\n",
    "<br>\n",
    "<center><img src=\"https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/image/mxnet_logo_2.png\" width=400></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import nd, autograd, gluon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home_and_Kitchen\n",
      "Books\n",
      "CDs_and_Vinyl\n",
      "Movies_and_TV\n",
      "Cell_Phones_and_Accessories\n",
      "Sports_and_Outdoors\n",
      "Clothing_Shoes_and_Jewelry\n"
     ]
    }
   ],
   "source": [
    "base_url = 'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/'\n",
    "prefix = 'reviews_'\n",
    "suffix = '_5.json.gz'\n",
    "folder = 'data'\n",
    "categories = [\n",
    "    'Home_and_Kitchen', \"\"\n",
    "    'Books', \n",
    "    'CDs_and_Vinyl', \n",
    "    'Movies_and_TV', \n",
    "    'Cell_Phones_and_Accessories',\n",
    "    'Sports_and_Outdoors', \n",
    "    'Clothing_Shoes_and_Jewelry'\n",
    "]\n",
    "!mkdir -p $folder\n",
    "for category in categories:\n",
    "    print(category)\n",
    "    url = base_url+prefix+category+suffix\n",
    "    !wget -P $folder $url -nc -nv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "1"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for line in g:\n",
    "        yield eval(line)\n",
    "\n",
    "def get_dataframe(path, num_lines):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        if i > num_lines:\n",
    "            break\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "\n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "MAX_ITEMS_PER_CATEGORY = 250000\n",
    "\n",
    "# Loading data from file if exist\n",
    "try:\n",
    "    data = pd.read_pickle('pickleddata.pkl')\n",
    "except:\n",
    "    data = None\n",
    "if data is None:\n",
    "    data = pd.DataFrame(data={'X':[],'Y':[]})\n",
    "    for index, category in enumerate(categories):\n",
    "        df = get_dataframe(\"{}/{}{}{}\".format(folder, prefix, category, suffix), MAX_ITEMS_PER_CATEGORY)    \n",
    "        # Each review's summary is prepended to the main review text\n",
    "        df = pd.DataFrame(data={'X':(df['summary']+' | '+df['reviewText'])[:MAX_ITEMS_PER_CATEGORY],'Y':index})\n",
    "        data = data.append(df)\n",
    "        print('{}:{} reviews'.format(category, len(df)))\n",
    "\n",
    "    # Shuffle the samples\n",
    "    data = data.sample(frac=1)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    # Saving the data in a pickled file\n",
    "    pd.to_pickle(data, 'pickleddata.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "2"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top red dot | Typical of Trijicon's high end p...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Viva Las Vegas - Blu-ray Info | Version: U.S.A...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nice color and quality! | Hubby loves this, gr...</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Great Album! | I had bought this album when it...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From No Dinner to King | One of Maurice Sendak...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   X    Y\n",
       "0  Top red dot | Typical of Trijicon's high end p...  5.0\n",
       "1  Viva Las Vegas - Blu-ray Info | Version: U.S.A...  3.0\n",
       "2  nice color and quality! | Hubby loves this, gr...  6.0\n",
       "3  Great Album! | I had bought this album when it...  2.0\n",
       "4  From No Dinner to King | One of Maurice Sendak...  1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gluon `Dataset` and `Dataloader `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon.data import ArrayDataset\n",
    "from mxnet.gluon.data import DataLoader\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "\n",
    "ALPHABET = list(\"abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:'\\\"/\\\\|_@#$%^&*~`+ =<>()[]{}\") # The 69 characters as specified in the paper\n",
    "ALPHABET_INDEX = {letter: index for index, letter in enumerate(ALPHABET)} # { a: 0, b: 1, etc}\n",
    "FEATURE_LEN = 1014 # max-length in characters for one document\n",
    "NUM_WORKERS = multiprocessing.cpu_count() # number of workers used in the data loading\n",
    "BATCH_SIZE = 128 # number of documents per batch\n",
    "\n",
    "def encode(text):\n",
    "    encoded = np.zeros([len(ALPHABET), FEATURE_LEN], dtype='float32')\n",
    "    review = text.lower()[:FEATURE_LEN-1:-1]\n",
    "    i = 0\n",
    "    for letter in text:\n",
    "        if i >= FEATURE_LEN:\n",
    "            break;\n",
    "        if letter in ALPHABET_INDEX:\n",
    "            encoded[ALPHABET_INDEX[letter]][i] = 1\n",
    "        i += 1\n",
    "    return encoded\n",
    "\n",
    "class AmazonDataSet(ArrayDataset):\n",
    "    # We pre-process the documents on the fly\n",
    "    def __getitem__(self, idx):\n",
    "        return encode(self._data[0][idx]), self._data[1][idx]\n",
    "    \n",
    "split = 0.8\n",
    "split_index = int(split*len(data))\n",
    "train_data_X = data['X'][:split_index].values\n",
    "train_data_Y = data['Y'][:split_index].values\n",
    "test_data_X = data['X'][split_index:].values\n",
    "test_data_Y = data['Y'][split_index:].values\n",
    "\n",
    "train_dataset = AmazonDataSet(train_data_X, train_data_Y)\n",
    "test_dataset = AmazonDataSet(test_data_X, test_data_Y)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, last_batch='discard')\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=True, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, last_batch='discard')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Create the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ctx = mx.gpu() # to run on GPU\n",
    "NUM_FILTERS = 256 # number of convolutional filters per convolutional layer\n",
    "NUM_OUTPUTS = len(categories) # number of classes\n",
    "FULLY_CONNECTED = 1024 # number of unit in the fully connected dense layer\n",
    "DROPOUT_RATE = 0.5 # probability of node drop out\n",
    "LEARNING_RATE = 0.01 # learning rate of the gradient\n",
    "MOMENTUM = 0.9 # momentum of the gradient\n",
    "WDECAY = 0.00001 # regularization term to limit size of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "net = gluon.nn.HybridSequential()\n",
    "with net.name_scope():\n",
    "    net.add(gluon.nn.Conv1D(channels=NUM_FILTERS, kernel_size=7, activation='relu'))\n",
    "    net.add(gluon.nn.MaxPool1D(pool_size=3, strides=3))\n",
    "    net.add(gluon.nn.Conv1D(channels=NUM_FILTERS, kernel_size=7, activation='relu'))\n",
    "    net.add(gluon.nn.MaxPool1D(pool_size=3, strides=3))\n",
    "    net.add(gluon.nn.Conv1D(channels=NUM_FILTERS, kernel_size=3, activation='relu'))\n",
    "    net.add(gluon.nn.Conv1D(channels=NUM_FILTERS, kernel_size=3, activation='relu'))\n",
    "    net.add(gluon.nn.Conv1D(channels=NUM_FILTERS, kernel_size=3, activation='relu'))\n",
    "    net.add(gluon.nn.Conv1D(channels=NUM_FILTERS, kernel_size=3, activation='relu'))\n",
    "    net.add(gluon.nn.MaxPool1D(pool_size=3, strides=3))\n",
    "    net.add(gluon.nn.Flatten())\n",
    "    net.add(gluon.nn.Dense(FULLY_CONNECTED, activation='relu'))\n",
    "    net.add(gluon.nn.Dropout(DROPOUT_RATE))\n",
    "    net.add(gluon.nn.Dense(FULLY_CONNECTED, activation='relu'))\n",
    "    net.add(gluon.nn.Dropout(DROPOUT_RATE))\n",
    "    net.add(gluon.nn.Dense(NUM_OUTPUTS))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Initialize Network Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "hybridize = True # for speed improvement, compile the network but no in-depth debugging possible\n",
    "load_params = False # Load pre-trained model\n",
    "\n",
    "if load_params:\n",
    "    net.load_params('crepe_gluon_epoch6.params', ctx=ctx)\n",
    "else:\n",
    "    net.collect_params().initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx)\n",
    "    \n",
    "if hybridize:\n",
    "    net.hybridize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', \n",
    "                        {'learning_rate': LEARNING_RATE, \n",
    "                         'wd':WDECAY, \n",
    "                         'momentum':MOMENTUM})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iterator, net):\n",
    "    acc = mx.metric.Accuracy()\n",
    "    for i, (data, label) in enumerate(data_iterator):\n",
    "        data = data.as_in_context(ctx)\n",
    "        label = label.as_in_context(ctx)\n",
    "        output = net(data)\n",
    "        prediction = nd.argmax(output, axis=1)\n",
    "\n",
    "        if (i%50 == 0):\n",
    "            print(\"Samples {}\".format(i*len(data)))\n",
    "        acc.update(preds=prediction, labels=label)\n",
    "    return acc.get()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0:1.9453378915786743,1.9453378915786743\n",
      "Batch 50:1.9373124837875366,1.943315461356685\n",
      "Batch 100:1.9081898927688599,1.932043050003778\n",
      "Batch 150:1.8508967161178589,1.9103771596963577\n",
      "Batch 200:1.9001646041870117,1.897644773367536\n",
      "Batch 250:1.898385763168335,1.893431542959099\n",
      "Batch 300:1.856143832206726,1.8850829157477298\n",
      "Batch 350:1.8237965106964111,1.880243124750212\n",
      "Batch 400:1.8509269952774048,1.8771633303411561\n",
      "Batch 450:1.8601528406143188,1.8749653442173433\n",
      "Batch 500:1.8604050874710083,1.8724235391005881\n",
      "Batch 550:1.8590565919876099,1.8718379428710714\n",
      "Batch 600:1.8669337034225464,1.8693746529364783\n",
      "Batch 650:1.8383421897888184,1.8681572097294508\n",
      "Batch 700:1.8637014627456665,1.8687037009062701\n",
      "Batch 750:1.824965000152588,1.8625427316355179\n",
      "Batch 800:1.878620982170105,1.8560348505611044\n",
      "Batch 850:1.8122719526290894,1.8397081812034204\n",
      "Batch 900:1.6698048114776611,1.8129354063315397\n",
      "Batch 950:1.6810656785964966,1.7841103058811965\n",
      "Batch 1000:1.6665819883346558,1.7381734343849182\n",
      "Batch 1050:1.9087369441986084,1.7972570259284935\n",
      "Batch 1100:1.9249498844146729,1.8330576966287526\n",
      "Batch 1150:1.848611831665039,1.8529058227425383\n",
      "Batch 1200:1.8461025953292847,1.8638277963046053\n",
      "Batch 1250:1.8916798830032349,1.8644350844218518\n",
      "Batch 1300:1.8725816011428833,1.866532087691531\n",
      "Batch 1350:1.9139583110809326,1.8665839722617905\n",
      "Batch 1400:1.8886419534683228,1.8700319859645074\n",
      "Batch 1450:1.871649980545044,1.8723657607944806\n",
      "Batch 1500:1.8444362878799438,1.8726145516597001\n",
      "Batch 1550:1.9569578170776367,1.8740631333724174\n",
      "Batch 1600:1.847110629081726,1.8682563343259702\n",
      "Batch 1650:1.8796321153640747,1.8707884232773702\n",
      "Batch 1700:1.8296846151351929,1.867869264999772\n",
      "Batch 1750:1.9194695949554443,1.8694412673397642\n",
      "Batch 1800:1.8853989839553833,1.8638438544336606\n",
      "Batch 1850:1.878685712814331,1.8634098309520748\n",
      "Batch 1900:1.86069917678833,1.858698771873116\n",
      "Batch 1950:1.7538530826568604,1.8365323374799165\n",
      "Batch 2000:1.7624948024749756,1.841136481176103\n",
      "Batch 2050:1.6832857131958008,1.8002076730009258\n",
      "Batch 2100:1.9362415075302124,1.809976246448211\n",
      "Batch 2150:1.5954055786132812,1.775792594988112\n",
      "Batch 2200:1.4584770202636719,1.6868196314080954\n",
      "Batch 2250:1.576601505279541,1.6216554992042063\n",
      "Batch 2300:1.4812443256378174,1.557055327590551\n",
      "Batch 2350:1.3834877014160156,1.502853024399113\n",
      "Batch 2400:1.336965799331665,1.456040571370033\n",
      "Batch 2450:1.2782310247421265,1.4145691765522772\n",
      "Batch 2500:1.3771641254425049,1.3936892664590668\n",
      "Batch 2550:1.2706668376922607,1.361659306358235\n",
      "Batch 2600:1.2734166383743286,1.3351345937998267\n",
      "Batch 2650:1.2477741241455078,1.304200714701585\n",
      "Batch 2700:1.2611356973648071,1.2788309453630742\n",
      "Batch 2750:1.2107969522476196,1.2864631086156533\n",
      "Batch 2800:1.1519348621368408,1.2732149880476045\n",
      "Batch 2850:1.1131393909454346,1.2486884570601255\n",
      "Batch 2900:1.2893774509429932,1.2235636463360515\n",
      "Batch 2950:1.3606523275375366,1.2095012342303335\n",
      "Batch 3000:1.2341409921646118,1.1875330016280221\n",
      "Batch 3050:1.1036291122436523,1.195664747555009\n",
      "Batch 3100:1.0621364116668701,1.1890826649339228\n",
      "Batch 3150:1.0590134859085083,1.1641739952794277\n",
      "Batch 3200:1.1681071519851685,1.1451550589781414\n",
      "Batch 3250:1.0229195356369019,1.1325940563554246\n",
      "Batch 3300:1.079014778137207,1.1141213653569366\n",
      "Batch 3350:1.2361879348754883,1.1159747056681775\n",
      "Batch 3400:1.205361008644104,1.105009222446501\n",
      "Batch 3450:1.1291594505310059,1.0983195917779331\n",
      "Batch 3500:1.064098596572876,1.087142925409798\n",
      "Batch 3550:1.099172830581665,1.0852045338908127\n",
      "Batch 3600:0.9594655632972717,1.0706505950584975\n",
      "Batch 3650:1.2273164987564087,1.0678795522641864\n",
      "Batch 3700:1.038029432296753,1.0568314232345457\n",
      "Batch 3750:1.0345441102981567,1.0514119130218187\n",
      "Batch 3800:1.0126543045043945,1.0367909375944986\n",
      "Batch 3850:1.1393961906433105,1.0301392440377153\n",
      "Batch 3900:1.0488090515136719,1.0106482383602724\n",
      "Batch 3950:0.9170652031898499,1.024482670403881\n",
      "Batch 4000:0.9427878856658936,1.0243950783226972\n",
      "Batch 4050:0.8843975067138672,0.9905536361093508\n",
      "Batch 4100:0.8888476490974426,1.0504400809502097\n",
      "Batch 4150:0.9303534626960754,1.0494979573971543\n",
      "Batch 4200:0.898644208908081,1.0341939556376147\n",
      "Batch 4250:0.7436461448669434,1.00889533177222\n",
      "Batch 4300:0.9273042678833008,0.9755362272484599\n",
      "Batch 4350:0.8877531886100769,0.9674427190319904\n",
      "Batch 4400:1.1328967809677124,0.9738816294062626\n",
      "Batch 4450:0.9573812484741211,0.9518427241266093\n",
      "Batch 4500:0.8913918137550354,0.9629289740318445\n",
      "Batch 4550:0.8544043898582458,0.9472341048191089\n",
      "Batch 4600:0.666782796382904,0.9243558497265563\n",
      "Batch 4650:0.8160680532455444,0.9065996666523378\n",
      "Batch 4700:0.9485316276550293,0.8833252974388099\n",
      "Batch 4750:0.8443765044212341,0.8680094950777169\n",
      "Batch 4800:0.8347811698913574,0.8624728163630457\n",
      "Batch 4850:0.8099501132965088,0.8490963395452955\n",
      "Batch 4900:0.7650530934333801,0.8265584423364825\n",
      "Batch 4950:0.8083596229553223,0.8211039998075594\n",
      "Batch 5000:0.8614997267723083,0.8259077664067933\n",
      "Batch 5050:0.7735437750816345,0.808474110675564\n",
      "Batch 5100:0.645978569984436,0.7982894140102011\n",
      "Batch 5150:0.7369328141212463,0.7927842614616121\n",
      "Batch 5200:0.7070375084877014,0.7947179728462571\n",
      "Batch 5250:0.7669934034347534,0.7793223107741862\n",
      "Batch 5300:0.648193359375,0.7605232354560412\n",
      "Batch 5350:0.7416223287582397,0.7585503382679126\n",
      "Batch 5400:0.7981933951377869,0.7482846768039738\n",
      "Batch 5450:0.6912879943847656,0.7435689229115255\n",
      "Batch 5500:0.7619497776031494,0.7363077731690414\n",
      "Batch 5550:0.5932537317276001,0.7089893360136923\n",
      "Batch 5600:0.7122735977172852,0.7135108894146994\n",
      "Batch 5650:0.7742758989334106,0.7011550385053558\n",
      "Batch 5700:0.5922141671180725,0.6874558257027454\n",
      "Batch 5750:0.553615927696228,0.6815414922093309\n",
      "Batch 5800:0.8475807309150696,0.708609440146428\n",
      "Batch 5850:0.5915058851242065,0.6824490589197143\n",
      "Batch 5900:0.6742552518844604,0.6640234860546748\n",
      "Batch 5950:0.6415994167327881,0.6708702698962937\n",
      "Batch 6000:0.7043026089668274,0.6593984448936463\n",
      "Batch 6050:0.7187190055847168,0.6541955304561856\n",
      "Batch 6100:0.596881091594696,0.6548190358955903\n",
      "Batch 6150:0.708433210849762,0.6339507446425041\n",
      "Batch 6200:0.65164715051651,0.6277746454389783\n",
      "Batch 6250:0.5474228262901306,0.6170153056710777\n",
      "Batch 6300:0.720673680305481,0.61511887096338\n",
      "Batch 6350:0.6575923562049866,0.6241926481620532\n",
      "Batch 6400:0.6677784323692322,0.6114716716673397\n",
      "Batch 6450:0.8161919116973877,0.6039949347469279\n",
      "Batch 6500:0.6343576908111572,0.5890953920229128\n",
      "Batch 6550:0.6406301856040955,0.5807989215002083\n",
      "Batch 6600:0.5672842860221863,0.5723362478117832\n",
      "Batch 6650:0.6819568872451782,0.5714187825095324\n",
      "Batch 6700:0.49000605940818787,0.571413701412841\n",
      "Batch 6750:0.5276893377304077,0.569738663706945\n",
      "Batch 6800:0.44463661313056946,0.5631019631472166\n",
      "Batch 6850:0.5261471271514893,0.5534414635015849\n",
      "Batch 6900:0.378284215927124,0.5506974315674976\n",
      "Batch 6950:0.5317144989967346,0.5534542084975974\n",
      "Batch 7000:0.4939468801021576,0.5386011991181794\n",
      "Batch 7050:0.4034293293952942,0.5394378124185936\n",
      "Batch 7100:0.6703130006790161,0.5385360586478665\n",
      "Batch 7150:0.42178627848625183,0.5430131880563699\n",
      "Batch 7200:0.5539587140083313,0.530087350948357\n",
      "Batch 7250:0.5476998686790466,0.5334676622804818\n",
      "Batch 7300:0.4491931200027466,0.5194388770565643\n",
      "Batch 7350:0.5936780571937561,0.5113525672951424\n",
      "Batch 7400:0.3533867597579956,0.5120763128701298\n",
      "Batch 7450:0.500450849533081,0.514983253922148\n",
      "Batch 7500:0.6001191139221191,0.5197977747576322\n",
      "Batch 7550:0.4414985477924347,0.5108791618496595\n",
      "Batch 7600:0.47784167528152466,0.511500274612454\n",
      "Batch 7650:0.6313395500183105,0.5135009335753875\n",
      "Batch 7700:0.4201299846172333,0.5044276278567247\n",
      "Batch 7750:0.43057698011398315,0.49498519543880104\n",
      "Batch 7800:0.421235591173172,0.49373594852094355\n",
      "Batch 7850:0.5850293040275574,0.4874337910059817\n",
      "Batch 7900:0.4728736877441406,0.49203616230162417\n",
      "Batch 7950:0.5296165943145752,0.4921089781533269\n",
      "Batch 8000:0.5693755745887756,0.4903399768488542\n",
      "Batch 8050:0.4520331025123596,0.4980184213887254\n",
      "Batch 8100:0.6577197909355164,0.4839749393634911\n",
      "Batch 8150:0.42644789814949036,0.4894406397049729\n",
      "Batch 8200:0.3823671042919159,0.4833629030072527\n",
      "Batch 8250:0.43571120500564575,0.4697571965284362\n",
      "Batch 8300:0.3432028591632843,0.4687206808578902\n",
      "Batch 8350:0.4749666452407837,0.4682180119457685\n",
      "Batch 8400:0.2713819444179535,0.456227908798264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 8450:0.47985485196113586,0.4639866777456651\n",
      "Batch 8500:0.5624803900718689,0.45303771419313277\n",
      "Batch 8550:0.5631905794143677,0.4521973165878254\n",
      "Batch 8600:0.4150260388851166,0.45121625314653013\n",
      "Batch 8650:0.4588847756385803,0.45476297943191973\n",
      "Batch 8700:0.5779296159744263,0.45991646032763606\n",
      "Batch 8750:0.4074401557445526,0.4517936186658269\n",
      "Batch 8800:0.3851879835128784,0.4411688010072596\n",
      "Batch 8850:0.47334063053131104,0.4395268303203959\n",
      "Batch 8900:0.4523012638092041,0.4448619439297806\n",
      "Batch 8950:0.32093507051467896,0.4485343687681969\n",
      "Batch 9000:0.40195515751838684,0.45140995653505167\n",
      "Batch 9050:0.33158352971076965,0.455498355086895\n",
      "Batch 9100:0.5638276934623718,0.44672403234999364\n",
      "Batch 9150:0.47881022095680237,0.4455053929735152\n",
      "Batch 9200:0.3218039274215698,0.43965251346516476\n",
      "Batch 9250:0.4617277979850769,0.4399941538302246\n",
      "Batch 9300:0.563423752784729,0.4386175812157087\n",
      "Batch 9350:0.5277352333068848,0.43751017413045534\n",
      "Batch 9400:0.34602174162864685,0.42652386636728107\n",
      "Batch 9450:0.46777939796447754,0.43991021726965296\n",
      "Batch 9500:0.4590960144996643,0.4342640066511467\n",
      "Batch 9550:0.38489675521850586,0.4213199904407998\n",
      "Batch 9600:0.371989369392395,0.42061784132023455\n",
      "Batch 9650:0.5260472297668457,0.4139681964267004\n",
      "Batch 9700:0.38143470883369446,0.41996656645431063\n",
      "Batch 9750:0.42192161083221436,0.4112546656773946\n",
      "Batch 9800:0.47223952412605286,0.4099760253046249\n",
      "Batch 9850:0.4302973747253418,0.40677251896893546\n",
      "Batch 9900:0.47169527411460876,0.4064781118619757\n",
      "Batch 9950:0.39229685068130493,0.4037787287140555\n",
      "Batch 10000:0.295209139585495,0.4060608509825546\n",
      "Batch 10050:0.4249939024448395,0.40307602987958785\n",
      "Batch 10100:0.3942011296749115,0.41462541100813466\n",
      "Batch 10150:0.3042117655277252,0.41182101740545635\n",
      "Batch 10200:0.3911605477333069,0.4111363044583184\n",
      "Batch 10250:0.3841712474822998,0.4055530627001431\n",
      "Batch 10300:0.3456384837627411,0.41033933155901303\n",
      "Batch 10350:0.5330745577812195,0.39953224418419725\n",
      "Batch 10400:0.5435792207717896,0.4007640746409533\n",
      "Batch 10450:0.3720492422580719,0.39730482342363294\n",
      "Batch 10500:0.40941375494003296,0.3907864438282218\n",
      "Batch 10550:0.3518534004688263,0.39271419239282945\n",
      "Samples 0\n",
      "Samples 6400\n",
      "Samples 12800\n",
      "Samples 19200\n",
      "Samples 25600\n",
      "Samples 32000\n",
      "Samples 38400\n",
      "Samples 44800\n",
      "Samples 51200\n",
      "Samples 57600\n",
      "Samples 64000\n",
      "Samples 70400\n",
      "Samples 76800\n",
      "Samples 83200\n",
      "Samples 89600\n",
      "Samples 96000\n",
      "Samples 102400\n",
      "Samples 108800\n",
      "Samples 115200\n",
      "Samples 121600\n",
      "Samples 128000\n",
      "Samples 134400\n",
      "Samples 140800\n",
      "Samples 147200\n",
      "Samples 153600\n",
      "Samples 160000\n",
      "Samples 166400\n",
      "Samples 172800\n",
      "Samples 179200\n",
      "Samples 185600\n",
      "Samples 192000\n",
      "Samples 198400\n",
      "Samples 204800\n",
      "Samples 211200\n",
      "Samples 217600\n",
      "Samples 224000\n",
      "Samples 230400\n",
      "Samples 236800\n",
      "Samples 243200\n",
      "Samples 249600\n",
      "Samples 256000\n",
      "Samples 262400\n",
      "Samples 268800\n",
      "Samples 275200\n",
      "Samples 281600\n",
      "Samples 300800\n",
      "Samples 307200\n",
      "Samples 313600\n",
      "Samples 320000\n",
      "Samples 326400\n",
      "Samples 332800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/gluon/block.py:345: UserWarning: save_params is deprecated. Please use save_parameters. Note that if you want load from SymbolBlock later, please use export instead. For details, see https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html\n",
      "  warnings.warn(\"save_params is deprecated. Please use save_parameters. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Loss: 0.3821500806238869, Test_acc 0.8727982149603325\n",
      "Batch 0:0.44937634468078613,0.44937634468078613\n",
      "Batch 50:0.31381672620773315,0.4315528630290391\n",
      "Batch 100:0.5040487051010132,0.41346983978772406\n",
      "Batch 150:0.415811151266098,0.40096860353549435\n",
      "Batch 200:0.45135796070098877,0.401574596858394\n",
      "Batch 250:0.42332765460014343,0.4076664222203996\n",
      "Batch 300:0.4372505843639374,0.3971096851432318\n",
      "Batch 350:0.3577941060066223,0.3925226119331721\n",
      "Batch 400:0.37929272651672363,0.3841495312693576\n",
      "Batch 450:0.3248221278190613,0.38793305058742067\n",
      "Batch 500:0.42874953150749207,0.3837092511906223\n",
      "Batch 550:0.43109965324401855,0.37953058307811355\n",
      "Batch 600:0.2747587263584137,0.37857862215626725\n",
      "Batch 650:0.25236496329307556,0.3780003708708689\n",
      "Batch 700:0.3362199366092682,0.38730630131123317\n",
      "Batch 750:0.4469776749610901,0.3942396399399915\n",
      "Batch 800:0.3710731565952301,0.38049545879708163\n",
      "Batch 850:0.29595208168029785,0.3823626289580725\n",
      "Batch 900:0.4009445011615753,0.3824267493705039\n",
      "Batch 950:0.5376309752464294,0.38094096153144896\n",
      "Batch 1000:0.4009401798248291,0.3807826434245483\n",
      "Batch 1050:0.3662900924682617,0.3836604591804354\n",
      "Batch 1100:0.30026495456695557,0.37182650253998034\n",
      "Batch 1150:0.28834086656570435,0.36943459892284203\n",
      "Batch 1200:0.25279954075813293,0.35994339538914943\n",
      "Batch 1250:0.32471320033073425,0.3657818126149851\n",
      "Batch 1300:0.22167740762233734,0.3680796444118444\n",
      "Batch 1350:0.4216146171092987,0.3762186177162488\n",
      "Batch 1400:0.27008697390556335,0.36944328119540526\n",
      "Batch 1450:0.32759007811546326,0.3745630339544264\n",
      "Batch 1500:0.5485547184944153,0.3705383812364658\n",
      "Batch 1550:0.3434290885925293,0.36150302938428486\n",
      "Batch 1600:0.40397608280181885,0.361096201353994\n",
      "Batch 1650:0.24847303330898285,0.3600953861374379\n",
      "Batch 1700:0.48536616563796997,0.36493712104717574\n",
      "Batch 1750:0.25833746790885925,0.3783770376387148\n",
      "Batch 1800:0.34508073329925537,0.3681881625924382\n",
      "Batch 1850:0.37404298782348633,0.36229298280661415\n",
      "Batch 1900:0.44818025827407837,0.36023010692571933\n",
      "Batch 1950:0.26633474230766296,0.3582290980493994\n",
      "Batch 2000:0.3772222101688385,0.3518669756661821\n",
      "Batch 2050:0.29658299684524536,0.35265674016767984\n",
      "Batch 2100:0.4115608334541321,0.3627027730864193\n",
      "Batch 2150:0.3321227431297302,0.3597440981954181\n",
      "Batch 2200:0.35763904452323914,0.361805100938518\n",
      "Batch 2250:0.32309502363204956,0.3649139867647389\n",
      "Batch 2300:0.35993632674217224,0.36940855559594676\n",
      "Batch 2350:0.3374985456466675,0.3748882425758905\n",
      "Batch 2400:0.45805031061172485,0.35997481530550735\n",
      "Batch 2450:0.3593754470348358,0.3585442228970738\n",
      "Batch 2500:0.45999157428741455,0.3543655919552738\n",
      "Batch 2550:0.3098708391189575,0.3550136856611144\n",
      "Batch 2600:0.3550087809562683,0.34550856337353725\n",
      "Batch 2650:0.27759066224098206,0.3482401575072023\n",
      "Batch 2700:0.30347082018852234,0.35158606303837525\n",
      "Batch 2750:0.4705715775489807,0.34868773694357663\n",
      "Batch 2800:0.3216540515422821,0.34890950561764766\n",
      "Batch 2850:0.24876174330711365,0.3392821255895321\n",
      "Batch 2900:0.3101179301738739,0.3399023471776407\n",
      "Batch 2950:0.3097124397754669,0.33593161075099076\n",
      "Batch 3000:0.42066866159439087,0.34150598448071756\n",
      "Batch 3050:0.361220121383667,0.33884599940262006\n",
      "Batch 3100:0.30624091625213623,0.3424734499534519\n",
      "Batch 3150:0.2657272219657898,0.341075468133255\n",
      "Batch 3200:0.28308582305908203,0.34295725358551427\n",
      "Batch 3250:0.21404778957366943,0.33826715732954266\n",
      "Batch 3300:0.2864799499511719,0.34164279557923777\n",
      "Batch 3350:0.3307136595249176,0.3443388716977357\n",
      "Batch 3400:0.3373100757598877,0.3358948994560604\n",
      "Batch 3450:0.4406742751598358,0.3412396220257551\n",
      "Batch 3500:0.372831791639328,0.3432947468810298\n",
      "Batch 3550:0.299345463514328,0.3420357769530747\n",
      "Batch 3600:0.30485957860946655,0.34263278317440304\n",
      "Batch 3650:0.27517664432525635,0.34463309356497823\n",
      "Batch 3700:0.34329408407211304,0.3441440476662934\n",
      "Batch 3750:0.2877465784549713,0.3408070954158174\n",
      "Batch 3800:0.3230522871017456,0.3304089187915363\n",
      "Batch 3850:0.27850818634033203,0.33559812486826013\n",
      "Batch 3900:0.32440653443336487,0.3265733569577985\n",
      "Batch 3950:0.30071157217025757,0.3275077887956533\n",
      "Batch 4000:0.4509875178337097,0.32574790713962964\n",
      "Batch 4050:0.3037916421890259,0.3215284499405636\n",
      "Batch 4100:0.2131553590297699,0.32668804297485976\n",
      "Batch 4150:0.23655754327774048,0.33892617596967506\n",
      "Batch 4200:0.39270415902137756,0.32769629231714015\n",
      "Batch 4250:0.2607485353946686,0.33190504163679085\n",
      "Batch 4300:0.3749202787876129,0.33682371019627355\n",
      "Batch 4350:0.4550178050994873,0.3472472596500284\n",
      "Batch 4400:0.33709394931793213,0.3361119164356006\n",
      "Batch 4450:0.33753958344459534,0.3404769242459154\n",
      "Batch 4500:0.31339943408966064,0.34094976348027967\n",
      "Batch 4550:0.24065887928009033,0.33845395327696715\n",
      "Batch 4600:0.3688552975654602,0.33740243167829626\n",
      "Batch 4650:0.3802257478237152,0.3396104152814373\n",
      "Batch 4700:0.47425299882888794,0.3314656519758878\n",
      "Batch 4750:0.3044627606868744,0.3312025410184706\n",
      "Batch 4800:0.4119078814983368,0.3348057991962722\n",
      "Batch 4850:0.31163808703422546,0.33569089702626703\n",
      "Batch 4900:0.24870765209197998,0.33361273383614487\n",
      "Batch 4950:0.29368388652801514,0.32550630311009565\n",
      "Batch 5000:0.2916813790798187,0.3331222312359345\n",
      "Batch 5050:0.3010379374027252,0.3389702456417147\n",
      "Batch 5100:0.2440338283777237,0.33717028601912297\n",
      "Batch 5150:0.3209361732006073,0.3303401760536018\n",
      "Batch 5200:0.22858355939388275,0.32526129241944457\n",
      "Batch 5250:0.2882072329521179,0.32724303440851715\n",
      "Batch 5300:0.2718082368373871,0.32957602912079687\n",
      "Batch 5350:0.25731995701789856,0.32550787032200024\n",
      "Batch 5400:0.4027693569660187,0.3217075136574155\n",
      "Batch 5450:0.3284948766231537,0.31903450895983015\n",
      "Batch 5500:0.355421781539917,0.3171061020272608\n",
      "Batch 5550:0.38238582015037537,0.31745002907442654\n",
      "Batch 5600:0.2813624441623688,0.3233288770603216\n",
      "Batch 5650:0.3283928334712982,0.3228887690400083\n",
      "Batch 5700:0.4140070974826813,0.32371173880145593\n",
      "Batch 5750:0.2141934335231781,0.3166247283780386\n",
      "Batch 5800:0.24746383726596832,0.31954655123652603\n",
      "Batch 5850:0.22340483963489532,0.32079573851040144\n",
      "Batch 5900:0.29580482840538025,0.3188458589819688\n",
      "Batch 5950:0.29286038875579834,0.31870474676922317\n",
      "Batch 6000:0.333731085062027,0.31729855845844285\n",
      "Batch 6050:0.49889904260635376,0.32188022569897057\n",
      "Batch 6100:0.2274465411901474,0.3240108414863729\n",
      "Batch 6150:0.2824826240539551,0.32223305288947324\n",
      "Batch 6200:0.351179301738739,0.32275705809707217\n",
      "Batch 6250:0.2177180051803589,0.3140313105158821\n",
      "Batch 6300:0.3248211443424225,0.31851833356416903\n",
      "Batch 6350:0.2263006865978241,0.3187551179484696\n",
      "Batch 6400:0.2866767346858978,0.32425780332362486\n",
      "Batch 6450:0.30262991786003113,0.32253375899014636\n",
      "Batch 6500:0.3546087443828583,0.3158385504938198\n",
      "Batch 6550:0.28694894909858704,0.3161402752018156\n",
      "Batch 6600:0.4106642007827759,0.31599989386761435\n",
      "Batch 6650:0.30898788571357727,0.31355458249156315\n",
      "Batch 6700:0.31676042079925537,0.3098626590052437\n",
      "Batch 6750:0.23306487500667572,0.3031887011554017\n",
      "Batch 6800:0.3078426122665405,0.3084751677185744\n",
      "Batch 6850:0.2648947536945343,0.31660265962805306\n",
      "Batch 6900:0.31409361958503723,0.3100119790866351\n",
      "Batch 6950:0.3217993676662445,0.31594882792185475\n",
      "Batch 7000:0.4681147634983063,0.31526575763763254\n",
      "Batch 7050:0.19052627682685852,0.3102650417734302\n",
      "Batch 7100:0.3809589743614197,0.3164679638765075\n",
      "Batch 7150:0.19822795689105988,0.31653248194660627\n",
      "Batch 7200:0.34903037548065186,0.31871271443296806\n",
      "Batch 7250:0.3493039608001709,0.31420895148585115\n",
      "Batch 7300:0.2107999473810196,0.31177148801525867\n",
      "Batch 7350:0.40219372510910034,0.30899896094882834\n",
      "Batch 7400:0.30962589383125305,0.31435841000436876\n",
      "Batch 7450:0.33069050312042236,0.31421733660841095\n",
      "Batch 7500:0.45405668020248413,0.3096784049753326\n",
      "Batch 7550:0.28291621804237366,0.3109185508369167\n",
      "Batch 7600:0.3569785952568054,0.3048387569471557\n",
      "Batch 7650:0.29359304904937744,0.3066684037348539\n",
      "Batch 7700:0.3174409866333008,0.30949412787460107\n",
      "Batch 7750:0.20645757019519806,0.3163274563712707\n",
      "Batch 7800:0.3446555733680725,0.31525199653477926\n",
      "Batch 7850:0.30156880617141724,0.3132078265212401\n",
      "Batch 7900:0.2923736572265625,0.30763237162436996\n",
      "Batch 7950:0.3029601275920868,0.30252493445608475\n",
      "Batch 8000:0.28734463453292847,0.3003387787835877\n",
      "Batch 8050:0.19801759719848633,0.2991570541900891\n",
      "Batch 8100:0.3508102297782898,0.29352522623988425\n",
      "Batch 8150:0.24224911630153656,0.2963748854241881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 8200:0.27197757363319397,0.2938076417783157\n",
      "Batch 8250:0.24859192967414856,0.29774192723110016\n",
      "Batch 8300:0.4467812776565552,0.30583694723425997\n",
      "Batch 8350:0.3217979371547699,0.3063755147864844\n",
      "Batch 8400:0.3140723407268524,0.2989789244329611\n",
      "Batch 8450:0.36514127254486084,0.30080671444435647\n",
      "Batch 8500:0.2110457867383957,0.29816959150269706\n",
      "Batch 8550:0.33561939001083374,0.30346683826666654\n",
      "Batch 8600:0.20255406200885773,0.30072598634120373\n",
      "Batch 8650:0.3557213842868805,0.3039880308379817\n",
      "Batch 8700:0.38020241260528564,0.30217133912626193\n",
      "Batch 8750:0.40684252977371216,0.30184438725076956\n",
      "Batch 8800:0.28492385149002075,0.3097588546899951\n",
      "Batch 8850:0.3415820598602295,0.31324004152512847\n",
      "Batch 8900:0.2536807060241699,0.3080846198178656\n",
      "Batch 8950:0.21727560460567474,0.3101559973648928\n",
      "Batch 9000:0.27118274569511414,0.304700698515511\n",
      "Batch 9050:0.38542383909225464,0.30189469605826175\n",
      "Batch 9100:0.2650977373123169,0.2984420310759431\n",
      "Batch 9150:0.2548796236515045,0.2952403091536996\n",
      "Batch 9200:0.1899561583995819,0.2984751329593362\n",
      "Batch 9250:0.47080889344215393,0.2960923119509665\n",
      "Batch 9300:0.35738077759742737,0.29569246849352554\n",
      "Batch 9350:0.2485038787126541,0.29135262234656684\n",
      "Batch 9400:0.17644371092319489,0.29611134358400887\n",
      "Batch 9450:0.33498474955558777,0.2965035385833063\n",
      "Batch 9500:0.22076304256916046,0.29748780759894994\n",
      "Batch 9550:0.24665388464927673,0.3088400772434069\n",
      "Batch 9600:0.41423895955085754,0.30576398455266984\n",
      "Batch 9650:0.29425185918807983,0.30869294562139066\n",
      "Batch 9700:0.2308518886566162,0.29781456565284076\n",
      "Batch 9750:0.22307135164737701,0.30222165360081166\n",
      "Batch 9800:0.20226603746414185,0.30288974254453754\n",
      "Batch 9850:0.4093194305896759,0.3035705236536192\n",
      "Batch 9900:0.3356260061264038,0.301125568499902\n",
      "Batch 9950:0.3212753236293793,0.2904653230351012\n",
      "Batch 10000:0.3316301703453064,0.28831515952357717\n",
      "Batch 10050:0.2091260552406311,0.2886836302752281\n",
      "Batch 10100:0.3622204065322876,0.29685666380388986\n",
      "Batch 10150:0.3178597092628479,0.299449831219007\n",
      "Batch 10200:0.2914865016937256,0.2936290422148521\n",
      "Batch 10250:0.32970795035362244,0.2989333559653086\n",
      "Batch 10300:0.36094072461128235,0.29755083771879476\n",
      "Batch 10350:0.3273831605911255,0.30008544185836433\n",
      "Batch 10400:0.322028785943985,0.29790796547944876\n",
      "Batch 10450:0.3033760190010071,0.297041654856552\n",
      "Batch 10500:0.34414446353912354,0.29638122311939247\n",
      "Batch 10550:0.21801714599132538,0.30014582608777507\n",
      "Samples 0\n",
      "Samples 6400\n",
      "Samples 12800\n",
      "Samples 19200\n",
      "Samples 25600\n",
      "Samples 32000\n",
      "Samples 38400\n",
      "Samples 44800\n",
      "Samples 51200\n",
      "Samples 57600\n",
      "Samples 64000\n",
      "Samples 70400\n",
      "Samples 76800\n",
      "Samples 83200\n",
      "Samples 89600\n",
      "Samples 96000\n",
      "Samples 102400\n",
      "Samples 108800\n",
      "Samples 115200\n",
      "Samples 121600\n",
      "Samples 128000\n",
      "Samples 134400\n",
      "Samples 140800\n",
      "Samples 147200\n",
      "Samples 153600\n",
      "Samples 160000\n",
      "Samples 166400\n",
      "Samples 172800\n",
      "Samples 179200\n",
      "Samples 185600\n",
      "Samples 192000\n",
      "Samples 198400\n",
      "Samples 204800\n",
      "Samples 211200\n",
      "Samples 217600\n",
      "Samples 224000\n",
      "Samples 230400\n",
      "Samples 236800\n",
      "Samples 243200\n",
      "Samples 249600\n",
      "Samples 256000\n",
      "Samples 262400\n",
      "Samples 268800\n",
      "Samples 275200\n",
      "Samples 281600\n",
      "Samples 288000\n",
      "Samples 294400\n",
      "Samples 300800\n",
      "Samples 307200\n",
      "Samples 313600\n",
      "Samples 320000\n",
      "Samples 326400\n",
      "Samples 332800\n",
      "Epoch 1. Loss: 0.3001864315685999, Test_acc 0.9020058084624103\n",
      "Batch 0:0.24389532208442688,0.24389532208442688\n",
      "Batch 50:0.325784832239151,0.2586787344769456\n",
      "Batch 100:0.2146085947751999,0.2628277209641395\n",
      "Batch 150:0.2666172981262207,0.27252360702779743\n",
      "Batch 200:0.26245996356010437,0.2880769219613049\n",
      "Batch 250:0.40386688709259033,0.2830308211011777\n",
      "Batch 300:0.23315051198005676,0.27544006115183506\n",
      "Batch 350:0.2627018392086029,0.2762612390742804\n",
      "Batch 400:0.33780983090400696,0.27798280559458965\n",
      "Batch 450:0.2679162621498108,0.281921711508827\n",
      "Batch 500:0.3112419545650482,0.28611537318739744\n",
      "Batch 550:0.22907112538814545,0.28360898402661183\n",
      "Batch 600:0.24258525669574738,0.28148815835290775\n",
      "Batch 650:0.25859424471855164,0.2826835274790733\n",
      "Batch 700:0.26166483759880066,0.28418870991560774\n",
      "Batch 750:0.26352885365486145,0.2842117147980361\n",
      "Batch 800:0.2498631477355957,0.2826849994775697\n",
      "Batch 850:0.4130362570285797,0.2850141520413276\n",
      "Batch 900:0.10792595893144608,0.27737056527292325\n",
      "Batch 950:0.23319590091705322,0.2803206991275476\n",
      "Batch 1000:0.2654478847980499,0.2826369928609116\n",
      "Batch 1050:0.2514944076538086,0.2827138861678057\n",
      "Batch 1100:0.2382391393184662,0.28370375458452374\n",
      "Batch 1150:0.39458727836608887,0.2821518402878568\n",
      "Batch 1200:0.3103829622268677,0.2865833142363184\n",
      "Batch 1250:0.3180133104324341,0.2948550337532052\n",
      "Batch 1300:0.3195689022541046,0.28592370672217593\n",
      "Batch 1350:0.3002873957157135,0.286924542467888\n",
      "Batch 1400:0.3002663850784302,0.285072585764602\n",
      "Batch 1450:0.3255915641784668,0.2902159499281058\n",
      "Batch 1500:0.2113618105649948,0.2878246275092136\n",
      "Batch 1550:0.2735356092453003,0.28667918539059795\n",
      "Batch 1600:0.30413490533828735,0.28275023352256273\n",
      "Batch 1650:0.26988309621810913,0.28619219427355336\n",
      "Batch 1700:0.2413489818572998,0.28402931360798905\n",
      "Batch 1750:0.22079028189182281,0.2769494779853746\n",
      "Batch 1800:0.2379024773836136,0.270886359067521\n",
      "Batch 1850:0.27917367219924927,0.28530545485579684\n",
      "Batch 1900:0.3325233459472656,0.28443848866658106\n",
      "Batch 1950:0.35135093331336975,0.2869923013789636\n",
      "Batch 2000:0.4625003933906555,0.2885266257499271\n",
      "Batch 2050:0.1908339262008667,0.28757478174972545\n",
      "Batch 2100:0.22459812462329865,0.28333287672886515\n",
      "Batch 2150:0.27188754081726074,0.27344006056602255\n",
      "Batch 2200:0.07369983196258545,0.266759819626562\n",
      "Batch 2250:0.23019979894161224,0.27388144006045434\n",
      "Batch 2300:0.3615531623363495,0.2775252765698517\n",
      "Batch 2350:0.24073748290538788,0.2756518229280619\n",
      "Batch 2400:0.3903508186340332,0.2763668241942538\n",
      "Batch 2450:0.38791799545288086,0.28460825827440783\n",
      "Batch 2500:0.22070923447608948,0.2807763855701895\n",
      "Batch 2550:0.24783144891262054,0.27667918841339645\n",
      "Batch 2600:0.4009864628314972,0.2791007653286036\n",
      "Batch 2650:0.3713567554950714,0.28279287463524827\n",
      "Batch 2700:0.31413009762763977,0.2852566309913404\n",
      "Batch 2750:0.23638106882572174,0.2769762735951579\n",
      "Batch 2800:0.3986603617668152,0.276042349101824\n",
      "Batch 2850:0.44738537073135376,0.28268350967404043\n",
      "Batch 2900:0.24290992319583893,0.2793450951897205\n",
      "Batch 2950:0.31956663727760315,0.2763096002511698\n",
      "Batch 3000:0.16677740216255188,0.27635660606573875\n",
      "Batch 3050:0.2774457335472107,0.2795049655634617\n",
      "Batch 3100:0.2928480803966522,0.2709160974921038\n",
      "Batch 3150:0.2797028422355652,0.2725420364110308\n",
      "Batch 3200:0.19959253072738647,0.27479061961583573\n",
      "Batch 3250:0.14500698447227478,0.2813927146588935\n",
      "Batch 3300:0.3021824359893799,0.28819599576404553\n",
      "Batch 3350:0.19785484671592712,0.2858163378527348\n",
      "Batch 3400:0.3313561975955963,0.28175672652274003\n",
      "Batch 3450:0.29443782567977905,0.2773878971064577\n",
      "Batch 3500:0.3823382258415222,0.27339226605579875\n",
      "Batch 3550:0.32984256744384766,0.27592153659976953\n",
      "Batch 3600:0.18163664638996124,0.2718002774499553\n",
      "Batch 3650:0.22607581317424774,0.2766328522689411\n",
      "Batch 3700:0.2746158838272095,0.2762925265851392\n",
      "Batch 3750:0.4352080523967743,0.27751505836276413\n",
      "Batch 3800:0.14471907913684845,0.2751856288472583\n",
      "Batch 3850:0.2994765639305115,0.27580765082717085\n",
      "Batch 3900:0.30641990900039673,0.27063613529267133\n",
      "Batch 3950:0.2263173758983612,0.27018549336888065\n",
      "Batch 4000:0.22882618010044098,0.2722683749821542\n",
      "Batch 4050:0.3178984224796295,0.27421002012590817\n",
      "Batch 4100:0.3191559612751007,0.27315774946587124\n",
      "Batch 4150:0.21957309544086456,0.2786425013459836\n",
      "Batch 4200:0.26798829436302185,0.28438618341766897\n",
      "Batch 4250:0.16700626909732819,0.277692190222051\n",
      "Batch 4300:0.4365226924419403,0.2759849092370108\n",
      "Batch 4350:0.31069353222846985,0.2752270087240525\n",
      "Batch 4400:0.19061988592147827,0.27742144978814554\n",
      "Batch 4450:0.32822385430336,0.2771206511292823\n",
      "Batch 4500:0.2545296251773834,0.2764112714029676\n",
      "Batch 4550:0.2857641279697418,0.2791567217193338\n",
      "Batch 4600:0.323574423789978,0.28444181856654066\n",
      "Batch 4650:0.3510372042655945,0.28152290929233675\n",
      "Batch 4700:0.19716843962669373,0.2805239101597545\n",
      "Batch 4750:0.42248284816741943,0.27851616033660953\n",
      "Batch 4800:0.2391899973154068,0.27739908915968853\n",
      "Batch 4850:0.2192850559949875,0.27340983187295037\n",
      "Batch 4900:0.20978981256484985,0.27500880084496554\n",
      "Batch 4950:0.27561792731285095,0.26939735943860604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5000:0.23960117995738983,0.26678315999411417\n",
      "Batch 5050:0.18233877420425415,0.2739831385381471\n",
      "Batch 5100:0.1879027932882309,0.27036730169424994\n",
      "Batch 5150:0.31666481494903564,0.27053240645172383\n",
      "Batch 5200:0.2565819323062897,0.27223647008471696\n",
      "Batch 5250:0.22163169085979462,0.2725995246321426\n",
      "Batch 5300:0.3513615131378174,0.27252098415952264\n",
      "Batch 5350:0.24110162258148193,0.27293656217397055\n",
      "Batch 5400:0.36442163586616516,0.2762353949269341\n",
      "Batch 5450:0.3137240707874298,0.27233790427669075\n",
      "Batch 5500:0.2466142177581787,0.2702187237109611\n",
      "Batch 5550:0.321842759847641,0.27121981425054176\n",
      "Batch 5600:0.22286559641361237,0.27569431176025777\n",
      "Batch 5650:0.270404577255249,0.27382083377147004\n",
      "Batch 5700:0.30897971987724304,0.27785335870446204\n",
      "Batch 5750:0.2224341183900833,0.27699410779504174\n",
      "Batch 5800:0.18850266933441162,0.2715292185845686\n",
      "Batch 5850:0.20904423296451569,0.2746270982438781\n",
      "Batch 5900:0.19491109251976013,0.2654337835249431\n",
      "Batch 5950:0.32512998580932617,0.26934879946195667\n",
      "Batch 6000:0.1930743157863617,0.2671549534690983\n",
      "Batch 6050:0.2916859984397888,0.26694037410029725\n",
      "Batch 6100:0.24924017488956451,0.2680271925061879\n",
      "Batch 6150:0.1703474074602127,0.267117004527971\n",
      "Batch 6200:0.18518005311489105,0.2666172419470577\n",
      "Batch 6250:0.16535478830337524,0.270229721071529\n",
      "Batch 6300:0.2841491401195526,0.26538511578091667\n",
      "Batch 6350:0.2724786698818207,0.2713307254903191\n",
      "Batch 6400:0.31332746148109436,0.2681848953628931\n",
      "Batch 6450:0.2610272765159607,0.262682224017855\n",
      "Batch 6500:0.38873693346977234,0.2605147509038568\n",
      "Batch 6550:0.1812513768672943,0.26682046212037597\n",
      "Batch 6600:0.25462186336517334,0.26453141709477607\n",
      "Batch 6650:0.3683561682701111,0.26778128815386754\n",
      "Batch 6700:0.3270961344242096,0.26283972343555345\n",
      "Batch 6750:0.3350801467895508,0.26668050456681325\n",
      "Batch 6800:0.24548447132110596,0.2712621104640966\n",
      "Batch 6850:0.31766727566719055,0.27223796975469444\n",
      "Batch 6900:0.3267132639884949,0.27690011628050487\n",
      "Batch 6950:0.15025587379932404,0.2689222562391922\n",
      "Batch 7000:0.25197088718414307,0.2622864648407595\n",
      "Batch 7050:0.3341063857078552,0.270948460157071\n",
      "Batch 7100:0.3584026098251343,0.27893748737255497\n",
      "Batch 7150:0.25142571330070496,0.2683033303586401\n",
      "Batch 7200:0.3676552474498749,0.2713967785215187\n",
      "Batch 7250:0.33119356632232666,0.27101015113830634\n",
      "Batch 7300:0.28625911474227905,0.26539264865661366\n",
      "Batch 7350:0.24496392905712128,0.2669394482255611\n",
      "Batch 7400:0.5019381046295166,0.2611727857596058\n",
      "Batch 7450:0.23070946335792542,0.27165519304733926\n",
      "Batch 7500:0.275518000125885,0.27362543929566224\n",
      "Batch 7550:0.2153550088405609,0.2738766140534462\n",
      "Batch 7600:0.18928059935569763,0.27772020777008843\n",
      "Batch 7650:0.3937223553657532,0.2739250419705579\n",
      "Batch 7700:0.2776116728782654,0.2733119187862863\n",
      "Batch 7750:0.23553761839866638,0.27751458034359117\n",
      "Batch 7800:0.3951435983181,0.28025713449106937\n",
      "Batch 7850:0.3051610589027405,0.27471423637744474\n",
      "Batch 7900:0.24249711632728577,0.2771514350857164\n",
      "Batch 7950:0.2848097085952759,0.2687835367438628\n",
      "Batch 8000:0.2728568911552429,0.27042794491067507\n",
      "Batch 8050:0.176426962018013,0.26345796446481184\n",
      "Batch 8100:0.30479666590690613,0.25996379002035547\n",
      "Batch 8150:0.3510069251060486,0.2625360708378555\n",
      "Batch 8200:0.3566380739212036,0.2662869418227322\n",
      "Batch 8250:0.25438064336776733,0.2673980258192122\n",
      "Batch 8300:0.24257154762744904,0.2647093481122714\n",
      "Batch 8350:0.34502941370010376,0.26612992124293183\n",
      "Batch 8400:0.21821385622024536,0.2638143565573993\n",
      "Batch 8450:0.1622968167066574,0.2673070897003368\n",
      "Batch 8500:0.30350279808044434,0.2700247784639415\n",
      "Batch 8550:0.30417367815971375,0.27118868276856173\n",
      "Batch 8600:0.16934314370155334,0.267807787073923\n",
      "Batch 8650:0.220625102519989,0.25965615826336663\n",
      "Batch 8700:0.18198902904987335,0.266952821600968\n",
      "Batch 8750:0.26831677556037903,0.26765608976039107\n",
      "Batch 8800:0.34735092520713806,0.2655925408733683\n",
      "Batch 8850:0.3106742203235626,0.27230094266698013\n",
      "Batch 8900:0.3598524034023285,0.27381578898499664\n",
      "Batch 8950:0.22972798347473145,0.26476956631955506\n",
      "Batch 9000:0.3064377009868622,0.2616691889374862\n",
      "Batch 9050:0.20856793224811554,0.2588693159415413\n",
      "Batch 9100:0.24879559874534607,0.253241584527725\n",
      "Batch 9150:0.2605421245098114,0.26138441156778686\n",
      "Batch 9200:0.16968652606010437,0.2612199521328504\n",
      "Batch 9250:0.33296602964401245,0.2663558583537154\n",
      "Batch 9300:0.29070112109184265,0.261816307007984\n",
      "Batch 9350:0.24536049365997314,0.26180676525558894\n",
      "Batch 9400:0.25004857778549194,0.2678958509845033\n",
      "Batch 9450:0.21803788840770721,0.2696445963603612\n",
      "Batch 9500:0.2862766683101654,0.2722162882546349\n",
      "Batch 9550:0.24725674092769623,0.27064123111957605\n",
      "Batch 9600:0.2532949149608612,0.2732750760911085\n",
      "Batch 9650:0.23532265424728394,0.26806431424794064\n",
      "Batch 9700:0.36434122920036316,0.2693617064859244\n",
      "Batch 9750:0.17852501571178436,0.2713534528491783\n",
      "Batch 9800:0.3063777983188629,0.2654785422524629\n",
      "Batch 9850:0.1262459009885788,0.2576221290918592\n",
      "Batch 9900:0.3587972819805145,0.2579713039147161\n",
      "Batch 9950:0.25477656722068787,0.26311323478498655\n",
      "Batch 10000:0.3612857162952423,0.2609355986747076\n",
      "Batch 10050:0.18464234471321106,0.2644138638630933\n",
      "Batch 10100:0.24187541007995605,0.26052462092427553\n",
      "Batch 10150:0.22697171568870544,0.2576175891656827\n",
      "Batch 10200:0.26148682832717896,0.2567138971783403\n",
      "Batch 10250:0.18679864704608917,0.25362400221467174\n",
      "Batch 10300:0.1689678281545639,0.2533100536201493\n",
      "Batch 10350:0.2977440059185028,0.25980623260618696\n",
      "Batch 10400:0.2879032492637634,0.25743298292747163\n",
      "Batch 10450:0.2036477029323578,0.25722285725398036\n",
      "Batch 10500:0.302598774433136,0.2620410529460535\n",
      "Batch 10550:0.24030166864395142,0.26818956808726485\n",
      "Samples 0\n",
      "Samples 6400\n",
      "Samples 12800\n",
      "Samples 19200\n",
      "Samples 25600\n",
      "Samples 32000\n",
      "Samples 38400\n",
      "Samples 44800\n",
      "Samples 51200\n",
      "Samples 57600\n",
      "Samples 64000\n",
      "Samples 70400\n",
      "Samples 76800\n",
      "Samples 83200\n",
      "Samples 89600\n",
      "Samples 96000\n",
      "Samples 102400\n",
      "Samples 108800\n",
      "Samples 115200\n",
      "Samples 121600\n",
      "Samples 128000\n",
      "Samples 134400\n",
      "Samples 140800\n",
      "Samples 147200\n",
      "Samples 153600\n",
      "Samples 160000\n",
      "Samples 166400\n",
      "Samples 172800\n",
      "Samples 179200\n",
      "Samples 185600\n",
      "Samples 192000\n",
      "Samples 198400\n",
      "Samples 204800\n",
      "Samples 211200\n",
      "Samples 217600\n",
      "Samples 224000\n",
      "Samples 230400\n",
      "Samples 236800\n",
      "Samples 243200\n",
      "Samples 249600\n",
      "Samples 256000\n",
      "Samples 262400\n",
      "Samples 268800\n",
      "Samples 275200\n",
      "Samples 281600\n",
      "Samples 288000\n",
      "Samples 294400\n",
      "Samples 300800\n",
      "Samples 307200\n",
      "Samples 313600\n",
      "Samples 320000\n",
      "Samples 326400\n",
      "Samples 332800\n",
      "Epoch 2. Loss: 0.2658297692131818, Test_acc 0.9091483282961843\n",
      "Batch 0:0.1941860467195511,0.1941860467195511\n",
      "Batch 50:0.31658872961997986,0.21671916520966203\n",
      "Batch 100:0.2521967589855194,0.23168199948149543\n",
      "Batch 150:0.19302250444889069,0.23979017760143725\n",
      "Batch 200:0.24496208131313324,0.2447981421328411\n",
      "Batch 250:0.28516334295272827,0.24211577530572284\n",
      "Batch 300:0.18693283200263977,0.24301996318025965\n",
      "Batch 350:0.2189895212650299,0.24859902272644158\n",
      "Batch 400:0.20521259307861328,0.25048870604729717\n",
      "Batch 450:0.4148041605949402,0.25088846556237077\n",
      "Batch 500:0.2142116129398346,0.25284004214304034\n",
      "Batch 550:0.3170224726200104,0.2566205333318217\n",
      "Batch 600:0.3889094591140747,0.25681040112501974\n",
      "Batch 650:0.27669093012809753,0.2621733340933789\n",
      "Batch 700:0.20086348056793213,0.25961322837771456\n",
      "Batch 750:0.2591976523399353,0.2583911537571793\n",
      "Batch 800:0.41967177391052246,0.25580296330081037\n",
      "Batch 850:0.16948257386684418,0.25189164068037273\n",
      "Batch 900:0.23992206156253815,0.2526241431147762\n",
      "Batch 950:0.31031015515327454,0.2571874954012715\n",
      "Batch 1000:0.2700868248939514,0.25499470465754387\n",
      "Batch 1050:0.1987900584936142,0.25233864230867714\n",
      "Batch 1100:0.18906667828559875,0.2479232542290969\n",
      "Batch 1150:0.3883070647716522,0.2526948534237064\n",
      "Batch 1200:0.22775164246559143,0.25342917999560477\n",
      "Batch 1250:0.22606457769870758,0.25441685776785217\n",
      "Batch 1300:0.299966037273407,0.2550424604006401\n",
      "Batch 1350:0.25975674390792847,0.2502732702534373\n",
      "Batch 1400:0.1689411699771881,0.2506024722340754\n",
      "Batch 1450:0.19306351244449615,0.2508266449095163\n",
      "Batch 1500:0.23085327446460724,0.24764974425082337\n",
      "Batch 1550:0.302992045879364,0.24463428269977613\n",
      "Batch 1600:0.25063610076904297,0.24228190108159814\n",
      "Batch 1650:0.22626250982284546,0.2471920358280924\n",
      "Batch 1700:0.2882711589336395,0.25377052899864366\n",
      "Batch 1750:0.31508809328079224,0.25448288389310586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1800:0.25570106506347656,0.25498207486616475\n",
      "Batch 1850:0.22478832304477692,0.249041745170119\n",
      "Batch 1900:0.3306662142276764,0.2519333822148582\n",
      "Batch 1950:0.2329009473323822,0.25270139868403363\n",
      "Batch 2000:0.19527964293956757,0.24814587946332373\n",
      "Batch 2050:0.3025817275047302,0.2546912552456034\n",
      "Batch 2100:0.1626625657081604,0.2540225265418582\n",
      "Batch 2150:0.1746119260787964,0.25465562180846796\n",
      "Batch 2200:0.19127564132213593,0.25329472867984537\n",
      "Batch 2250:0.2373402863740921,0.2583443649528398\n",
      "Batch 2300:0.18735381960868835,0.24979576143362756\n",
      "Batch 2350:0.15668439865112305,0.2507421750142421\n",
      "Batch 2400:0.3740532696247101,0.25605786834900135\n",
      "Batch 2450:0.2778483033180237,0.2550493547884093\n",
      "Batch 2500:0.20838014781475067,0.24735780700297047\n",
      "Batch 2550:0.2590154707431793,0.25013863184484303\n",
      "Batch 2600:0.2852047383785248,0.24776964599576956\n",
      "Batch 2650:0.29664602875709534,0.2518563234850922\n",
      "Batch 2700:0.22017504274845123,0.24788587227752631\n",
      "Batch 2750:0.203706294298172,0.24617865405502198\n",
      "Batch 2800:0.27547064423561096,0.24667078749730248\n",
      "Batch 2850:0.2929142415523529,0.2485286002224891\n",
      "Batch 2900:0.42012593150138855,0.2538956799798522\n",
      "Batch 2950:0.23708103597164154,0.24768661355853572\n",
      "Batch 3000:0.2638615071773529,0.2520739441020755\n",
      "Batch 3050:0.2233738750219345,0.25469647394941075\n",
      "Batch 3100:0.2240043431520462,0.2570876643913988\n",
      "Batch 3150:0.29350391030311584,0.25314837831786413\n",
      "Batch 3200:0.19728218019008636,0.25328337753342195\n",
      "Batch 3250:0.21053767204284668,0.24833660897111243\n",
      "Batch 3300:0.18756085634231567,0.24390339052413182\n",
      "Batch 3350:0.2670709788799286,0.24722672847103877\n",
      "Batch 3400:0.2826414108276367,0.24559135485713188\n",
      "Batch 3450:0.2898506820201874,0.24795786271438133\n",
      "Batch 3500:0.37055763602256775,0.24856024820744368\n",
      "Batch 3550:0.4155183434486389,0.25229063498093157\n",
      "Batch 3600:0.47978973388671875,0.2557151581384231\n",
      "Batch 3650:0.19740815460681915,0.2537981381595368\n",
      "Batch 3700:0.20121270418167114,0.2529426036933683\n",
      "Batch 3750:0.20758366584777832,0.24850124665283554\n",
      "Batch 3800:0.19935579597949982,0.2520821829803755\n",
      "Batch 3850:0.27685636281967163,0.25690457915857473\n",
      "Batch 3900:0.23223961889743805,0.25336043803056657\n",
      "Batch 3950:0.1703963726758957,0.2528621125940948\n",
      "Batch 4000:0.21939799189567566,0.24861530735104345\n",
      "Batch 4050:0.42607006430625916,0.2523615909289689\n",
      "Batch 4100:0.28360095620155334,0.24977069986504305\n",
      "Batch 4150:0.23916684091091156,0.25135281311629043\n",
      "Batch 4200:0.18861770629882812,0.25286859921510163\n",
      "Batch 4250:0.3638722896575928,0.253518125875652\n",
      "Batch 4300:0.20404872298240662,0.2473049770017196\n",
      "Batch 4350:0.16226743161678314,0.24609152754393895\n",
      "Batch 4400:0.24503867328166962,0.2433434280110366\n",
      "Batch 4450:0.32394900918006897,0.25073867966223307\n",
      "Batch 4500:0.23521536588668823,0.2449454776010514\n",
      "Batch 4550:0.21826858818531036,0.24850385982135736\n",
      "Batch 4600:0.3641389310359955,0.2462022260364421\n",
      "Batch 4650:0.2597631812095642,0.2416672158727447\n",
      "Batch 4700:0.26972538232803345,0.2458592796350883\n",
      "Batch 4750:0.23873959481716156,0.24498496663549582\n",
      "Batch 4800:0.3225412666797638,0.2483016926200805\n",
      "Batch 4850:0.2092646062374115,0.2495066089502207\n",
      "Batch 4900:0.33522793650627136,0.2480378341605821\n",
      "Batch 4950:0.2803383767604828,0.2493724456513337\n",
      "Batch 5000:0.3681379556655884,0.24797561572494384\n",
      "Batch 8100:0.20162709057331085,0.23312360684790406\n",
      "Batch 8150:0.14563977718353271,0.23168360825505363\n",
      "Batch 8200:0.2133028507232666,0.22719560633391822\n",
      "Batch 8250:0.17351587116718292,0.22400962818352319\n",
      "Batch 8300:0.2811063826084137,0.22284463124768744\n",
      "Batch 8350:0.14553137123584747,0.21975719117967535\n",
      "Batch 8400:0.28504353761672974,0.2268275926850399\n",
      "Batch 8450:0.25765982270240784,0.22987545284216387\n",
      "Batch 8500:0.23935215175151825,0.22658240896558807\n",
      "Batch 8550:0.1359587460756302,0.22858798091093344\n",
      "Batch 8600:0.2730662524700165,0.23414688210305493\n",
      "Batch 8650:0.2182261198759079,0.24364246777565707\n",
      "Batch 8700:0.308156818151474,0.2368106104350439\n",
      "Batch 8750:0.20430657267570496,0.23069927661746403\n",
      "Batch 8800:0.09492097049951553,0.22740119576929066\n",
      "Batch 8850:0.2106761485338211,0.22782187893898267\n",
      "Batch 8900:0.13661032915115356,0.22832812224779628\n",
      "Batch 8950:0.15181559324264526,0.2249728954190214\n",
      "Batch 9000:0.2257855385541916,0.22323553915261427\n",
      "Batch 9050:0.21335606276988983,0.22435622271791644\n",
      "Batch 9100:0.21570871770381927,0.23083918252611324\n",
      "Batch 9150:0.28465425968170166,0.23514869636729538\n",
      "Batch 9200:0.3396376073360443,0.24072683202076803\n",
      "Batch 9250:0.1610269397497177,0.23631854106823336\n",
      "Batch 9300:0.2684153616428375,0.22972107686310414\n",
      "Batch 9350:0.17266908288002014,0.22236477866042\n",
      "Batch 9400:0.15569299459457397,0.22625076353283927\n",
      "Batch 9450:0.2674064636230469,0.22647951919484552\n",
      "Batch 9500:0.21164992451667786,0.22200029082580144\n",
      "Batch 9550:0.25766947865486145,0.2240320772818353\n",
      "Batch 9600:0.1867002248764038,0.21924935673192003\n",
      "Batch 9650:0.23119911551475525,0.21490698871611394\n",
      "Batch 9700:0.21497748792171478,0.21990753481380157\n",
      "Batch 9750:0.3114003539085388,0.2298017187809157\n",
      "Batch 9800:0.1599075049161911,0.23005514256245646\n",
      "Batch 9850:0.2826938331127167,0.23422239972132386\n",
      "Batch 9900:0.1929677575826645,0.2320168752560156\n",
      "Batch 9950:0.2613004446029663,0.23089628190269662\n",
      "Batch 10000:0.22803372144699097,0.2323713773466675\n",
      "Batch 10050:0.21061009168624878,0.22810357577051854\n",
      "Batch 10100:0.2478046417236328,0.22740542494969845\n",
      "Batch 10150:0.23070217669010162,0.2307595822243832\n",
      "Batch 10200:0.2577609717845917,0.2259073669415289\n",
      "Batch 10250:0.17951707541942596,0.23014435936609173\n",
      "Batch 10300:0.3534074127674103,0.2303898642548033\n",
      "Batch 10350:0.24307145178318024,0.22963219691024067\n",
      "Batch 10400:0.1287955790758133,0.22914991211049887\n",
      "Batch 10450:0.2222599983215332,0.22646955047018633\n",
      "Batch 10500:0.13454008102416992,0.23308208017517545\n",
      "Batch 10550:0.3188818693161011,0.23120967844251097\n",
      "Samples 0\n",
      "Samples 6400\n",
      "Samples 12800\n",
      "Samples 19200\n",
      "Samples 25600\n",
      "Samples 32000\n",
      "Samples 38400\n",
      "Samples 44800\n",
      "Samples 51200\n",
      "Samples 57600\n",
      "Samples 64000\n",
      "Samples 70400\n",
      "Samples 76800\n",
      "Samples 83200\n",
      "Samples 89600\n",
      "Samples 96000\n",
      "Samples 102400\n",
      "Samples 108800\n",
      "Samples 115200\n",
      "Samples 121600\n",
      "Samples 128000\n",
      "Samples 134400\n",
      "Samples 140800\n",
      "Samples 147200\n",
      "Samples 153600\n",
      "Samples 160000\n",
      "Samples 166400\n",
      "Samples 172800\n",
      "Samples 179200\n",
      "Samples 185600\n",
      "Samples 192000\n",
      "Samples 198400\n",
      "Samples 204800\n",
      "Samples 211200\n",
      "Samples 217600\n",
      "Samples 224000\n",
      "Samples 230400\n",
      "Samples 236800\n",
      "Samples 243200\n",
      "Samples 249600\n",
      "Samples 256000\n",
      "Samples 262400\n",
      "Samples 268800\n",
      "Samples 275200\n",
      "Samples 281600\n",
      "Samples 288000\n",
      "Samples 294400\n",
      "Samples 300800\n",
      "Samples 307200\n",
      "Samples 313600\n",
      "Samples 320000\n",
      "Samples 326400\n",
      "Samples 332800\n",
      "Epoch 4. Loss: 0.2299152824859961, Test_acc 0.9183834293539856\n",
      "Batch 0:0.24427418410778046,0.24427418410778046\n",
      "Batch 50:0.2679714262485504,0.22897198315080705\n",
      "Batch 100:0.24202950298786163,0.22162527477916674\n",
      "Batch 150:0.15879692137241364,0.2184306402944804\n",
      "Batch 200:0.35412684082984924,0.22127270649871164\n",
      "Batch 250:0.16805116832256317,0.2197751006915107\n",
      "Batch 300:0.13398870825767517,0.21968182983321252\n",
      "Batch 350:0.1370643526315689,0.21476000271435117\n",
      "Batch 400:0.1498461663722992,0.2131568631680802\n",
      "Batch 450:0.08613952249288559,0.2091389972690554\n",
      "Batch 500:0.22877712547779083,0.213567599046376\n",
      "Batch 550:0.15652692317962646,0.21215200114200822\n",
      "Batch 600:0.22600050270557404,0.2204165033917301\n",
      "Batch 650:0.3138068616390228,0.22533191100841318\n",
      "Batch 700:0.1484944224357605,0.22439856871296437\n",
      "Batch 750:0.17814360558986664,0.2215307548759212\n",
      "Batch 800:0.13337655365467072,0.2156075812827405\n",
      "Batch 850:0.3901336193084717,0.21855267381251667\n",
      "Batch 900:0.32425346970558167,0.21627055721941654\n",
      "Batch 950:0.18094493448734283,0.20972612686388264\n",
      "Batch 1000:0.2519332766532898,0.21199373995872728\n",
      "Batch 1050:0.19025090336799622,0.2186100833641878\n",
      "Batch 1100:0.17488959431648254,0.21771450773621215\n",
      "Batch 1150:0.27191925048828125,0.21664193280204505\n",
      "Batch 1200:0.2913120985031128,0.21066323066260126\n",
      "Batch 1250:0.27970823645591736,0.21322953384162266\n",
      "Batch 1300:0.19248904287815094,0.21226549417837187\n",
      "Batch 1350:0.1533055603504181,0.21148445917480332\n",
      "Batch 1400:0.24366693198680878,0.2097916282243038\n",
      "Batch 1450:0.14577600359916687,0.21164585104786382\n",
      "Batch 1500:0.20090234279632568,0.21010066726216192\n",
      "Batch 1550:0.10120023041963577,0.20788697626229002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1600:0.20007918775081635,0.2183053314267211\n",
      "Batch 1650:0.18667852878570557,0.21653213823534814\n",
      "Batch 1700:0.11753082275390625,0.21446947017305065\n",
      "Batch 1750:0.24922433495521545,0.21774810693336796\n",
      "Batch 1800:0.24191629886627197,0.21641898640458918\n",
      "Batch 1850:0.14448727667331696,0.2175660210506627\n",
      "Batch 1900:0.1582629382610321,0.21565621060041806\n",
      "Batch 1950:0.17554453015327454,0.21167943307307924\n",
      "Batch 2000:0.2131025195121765,0.21584835668911015\n",
      "Batch 2050:0.28586122393608093,0.21716183769788053\n",
      "Batch 2100:0.1828976571559906,0.21639496853454113\n",
      "Batch 2150:0.19319458305835724,0.22190682061886674\n",
      "Batch 2200:0.23728948831558228,0.21307741505647085\n",
      "Batch 2250:0.19557172060012817,0.21317052838109618\n",
      "Batch 2300:0.21660135686397552,0.21429414246255749\n",
      "Batch 2350:0.18677692115306854,0.21088851094425246\n",
      "Batch 2400:0.2642718255519867,0.21098130044964358\n",
      "Batch 2450:0.14746440947055817,0.21967465643049044\n",
      "Batch 2500:0.2861218750476837,0.2259039073392661\n",
      "Batch 2550:0.14257875084877014,0.22579672397944267\n",
      "Batch 2600:0.1297900378704071,0.2215537761935028\n",
      "Batch 2650:0.1998727172613144,0.21595207738473485\n",
      "Batch 2700:0.1850435435771942,0.21522457199362927\n",
      "Batch 2750:0.17000260949134827,0.21633402343952365\n",
      "Batch 2800:0.1716529130935669,0.21826518596887795\n",
      "Batch 2850:0.20378878712654114,0.22056552796102305\n",
      "Batch 2900:0.19459030032157898,0.22370241926472487\n",
      "Batch 2950:0.2804645895957947,0.2195141316124081\n",
      "Batch 3000:0.28311124444007874,0.22151384397640997\n",
      "Batch 3050:0.21010686457157135,0.21671033033156512\n",
      "Batch 3100:0.1958736777305603,0.21463464245252645\n",
      "Batch 3150:0.2871691882610321,0.22238219019246394\n",
      "Batch 3200:0.19219541549682617,0.21929415703574318\n",
      "Batch 3250:0.0958605706691742,0.2186370071750593\n",
      "Batch 3300:0.17396065592765808,0.21217205526539373\n",
      "Batch 3350:0.15142373740673065,0.21217903186115208\n",
      "Batch 3400:0.28016918897628784,0.21529021608347879\n",
      "Batch 3450:0.1987280547618866,0.21930620107566404\n",
      "Batch 3500:0.21128666400909424,0.21759219840955552\n",
      "Batch 3550:0.17842303216457367,0.2229435803017188\n",
      "Batch 3600:0.2800770103931427,0.21955611200076408\n",
      "Batch 3650:0.24934571981430054,0.21618053374892637\n",
      "Batch 3700:0.19538256525993347,0.22115017224833994\n",
      "Batch 3750:0.17786121368408203,0.22045218599429792\n",
      "Batch 3800:0.32289108633995056,0.2164697321378988\n",
      "Batch 3850:0.27170225977897644,0.2156726318420873\n",
      "Batch 3900:0.28420019149780273,0.21674164982415964\n",
      "Batch 3950:0.13907882571220398,0.21039544669364485\n",
      "Batch 4000:0.2516492009162903,0.21473575097587078\n",
      "Batch 4050:0.15727278590202332,0.21471894108001832\n",
      "Batch 4100:0.18160264194011688,0.2129130967538405\n",
      "Batch 4150:0.1971186250448227,0.21250869021775454\n",
      "Batch 4200:0.12936630845069885,0.22259467485704637\n",
      "Batch 4250:0.28760018944740295,0.21774585324546888\n",
      "Batch 4300:0.2110646367073059,0.21546515012913778\n",
      "Batch 4350:0.1683822125196457,0.21042908546863334\n",
      "Batch 4400:0.3563787043094635,0.21644615672937562\n",
      "Batch 4450:0.23408947885036469,0.21935095805563598\n",
      "Batch 4500:0.24593524634838104,0.22132126644106148\n",
      "Batch 4550:0.1744009554386139,0.21649951105624696\n",
      "Batch 4600:0.2794977128505707,0.21504920023756968\n",
      "Batch 4650:0.18391866981983185,0.217253577433126\n",
      "Batch 4700:0.3013894557952881,0.22146927718990514\n",
      "Batch 4750:0.3080529570579529,0.21334830458742193\n",
      "Batch 4800:0.22236935794353485,0.21437262791199813\n",
      "Batch 4850:0.24181517958641052,0.21564279552414317\n",
      "Batch 4900:0.09221069514751434,0.2114904360630342\n",
      "Batch 4950:0.16109821200370789,0.21241362157257707\n",
      "Batch 5000:0.16261442005634308,0.21389432632403035\n",
      "Batch 5050:0.2745799720287323,0.2137278623398073\n",
      "Batch 5100:0.2107389122247696,0.21684911366317153\n",
      "Batch 5150:0.2536778748035431,0.21412130664371357\n",
      "Batch 5200:0.21468211710453033,0.21203112237586175\n",
      "Batch 5250:0.2304316610097885,0.21083873720221732\n",
      "Batch 5300:0.2696201503276825,0.21465599224892207\n",
      "Batch 5350:0.26954007148742676,0.21487176944983083\n",
      "Batch 5400:0.18473416566848755,0.21915726984205178\n",
      "Batch 5450:0.23795261979103088,0.22036814468229426\n",
      "Batch 5500:0.17209063470363617,0.2129858039583942\n",
      "Batch 5550:0.20081329345703125,0.2207616024443681\n",
      "Batch 5600:0.19728145003318787,0.21715943603237303\n",
      "Batch 5650:0.20564474165439606,0.22063404824068783\n",
      "Batch 5700:0.17708992958068848,0.2160431297056789\n",
      "Batch 5750:0.35763370990753174,0.2074235411286257\n",
      "Batch 5800:0.3696575462818146,0.20904687769141164\n",
      "Batch 5850:0.32486996054649353,0.21612288498971768\n",
      "Batch 5900:0.23955942690372467,0.2113546883009917\n",
      "Batch 5950:0.4194986820220947,0.2178061162671623\n",
      "Batch 6000:0.19883058965206146,0.21823633392910008\n",
      "Batch 6050:0.12606236338615417,0.21882258911999358\n",
      "Batch 6100:0.1713895946741104,0.21676697195303987\n",
      "Batch 6150:0.19056570529937744,0.2200779177741412\n",
      "Batch 6200:0.21344216167926788,0.21773923844357382\n",
      "Batch 6250:0.13601022958755493,0.21679633656354394\n",
      "Batch 6300:0.13543659448623657,0.2166087499778769\n",
      "Batch 6350:0.11936016380786896,0.21588964281406714\n",
      "Batch 6400:0.22208797931671143,0.21634907406505527\n",
      "Batch 6450:0.23851658403873444,0.21945040293851953\n",
      "Batch 6500:0.18007569015026093,0.2152954386288373\n",
      "Batch 6550:0.17212606966495514,0.22033901216878574\n",
      "Batch 6600:0.17481572926044464,0.2244445213430341\n",
      "Batch 6650:0.22294911742210388,0.2253342302452441\n",
      "Batch 6700:0.23355673253536224,0.21838328732087364\n",
      "Batch 6750:0.21775409579277039,0.21426213855019807\n",
      "Batch 6800:0.18189972639083862,0.21213749153397699\n",
      "Batch 6850:0.14339132606983185,0.21453757066599452\n",
      "Batch 6900:0.13255789875984192,0.21332998956915414\n",
      "Batch 6950:0.21819688379764557,0.21072461458255468\n",
      "Batch 7000:0.28063666820526123,0.21072702130380488\n",
      "Batch 7050:0.11533155292272568,0.21457311268756726\n",
      "Batch 7100:0.10955643653869629,0.21310835181970672\n",
      "Batch 7150:0.25383666157722473,0.2210862487348383\n",
      "Batch 7200:0.21343444287776947,0.21405825774334655\n",
      "Batch 7250:0.32845407724380493,0.21316019609203424\n",
      "Batch 7300:0.23497718572616577,0.21316652803078698\n",
      "Batch 7350:0.21169516444206238,0.20860993705453626\n",
      "Batch 7400:0.21751141548156738,0.21592846396671295\n",
      "Batch 7450:0.1571945697069168,0.21519792366709914\n",
      "Batch 7500:0.2174902856349945,0.2166193383495918\n",
      "Batch 7550:0.23031076788902283,0.21454016453790917\n",
      "Batch 7600:0.22037841379642487,0.2092911239222622\n",
      "Batch 7650:0.22037440538406372,0.20624843392261433\n",
      "Batch 7700:0.22723741829395294,0.2056810649326675\n",
      "Batch 7750:0.21320390701293945,0.20997647862751087\n",
      "Batch 7800:0.21985310316085815,0.21560299886862833\n",
      "Batch 7850:0.13401056826114655,0.211880350072839\n",
      "Batch 7900:0.3082793056964874,0.2178709132820786\n",
      "Batch 7950:0.22695057094097137,0.2194934098783305\n",
      "Batch 8000:0.35470157861709595,0.22606207371621914\n",
      "Batch 8050:0.194588303565979,0.21849735283258245\n",
      "Batch 8100:0.13956117630004883,0.22348246358362533\n",
      "Batch 8150:0.1899799108505249,0.22264740294464375\n",
      "Batch 8200:0.2328541874885559,0.22125725406532606\n",
      "Batch 8250:0.2222023457288742,0.21831799749051997\n",
      "Batch 8300:0.3517382740974426,0.22515507710481153\n",
      "Batch 8350:0.16922448575496674,0.22398178085873713\n",
      "Batch 8400:0.2210257649421692,0.219419162837078\n",
      "Batch 8450:0.14506946504116058,0.21974953698202826\n",
      "Batch 8500:0.15322935581207275,0.21980968674006485\n",
      "Batch 8550:0.30751025676727295,0.2216225692166925\n",
      "Batch 8600:0.20344612002372742,0.22213862600856132\n",
      "Batch 8650:0.15781477093696594,0.21871573179865322\n",
      "Batch 8700:0.21726924180984497,0.21862068627295467\n",
      "Batch 8750:0.18855509161949158,0.21749235134707234\n",
      "Batch 8800:0.14214608073234558,0.21892743156743397\n",
      "Batch 8850:0.22055746614933014,0.21959596158954364\n",
      "Batch 8900:0.15310631692409515,0.2194311366056149\n",
      "Batch 8950:0.146728977560997,0.21571768252209117\n",
      "Batch 9000:0.25663942098617554,0.21812054491164712\n",
      "Batch 9050:0.2307216227054596,0.22236062247165417\n",
      "Batch 9100:0.22426466643810272,0.22170120252488942\n",
      "Batch 9150:0.2619721591472626,0.21615125884162906\n",
      "Batch 9200:0.1292310357093811,0.2163304549538655\n",
      "Batch 9250:0.21112853288650513,0.2109838113620484\n",
      "Batch 9300:0.2015516310930252,0.21541247568911098\n",
      "Batch 9350:0.205147385597229,0.20621424186317147\n",
      "Batch 9400:0.25571131706237793,0.20964316460303656\n",
      "Batch 9450:0.19704516232013702,0.21419337579995376\n",
      "Batch 9500:0.137640118598938,0.21019814325651912\n",
      "Batch 9550:0.2642749845981598,0.2207815577886005\n",
      "Batch 9600:0.17374537885189056,0.22378909799560018\n",
      "Batch 9650:0.2148308902978897,0.22543581561616083\n",
      "Batch 9700:0.1521589607000351,0.22507463002159542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 9750:0.12800079584121704,0.22505619937549612\n",
      "Batch 9800:0.22445355355739594,0.2225041026835433\n",
      "Batch 9850:0.11865705251693726,0.21613074270182328\n",
      "Batch 9900:0.14949725568294525,0.21989401321667415\n",
      "Batch 9950:0.11306945979595184,0.22114477012527084\n",
      "Batch 10000:0.22535301744937897,0.21986543788699028\n",
      "Batch 10050:0.18214204907417297,0.22155672924752018\n",
      "Batch 10100:0.1939678192138672,0.21912238921846042\n",
      "Batch 10150:0.15101201832294464,0.21705893319549227\n",
      "Batch 10200:0.15143752098083496,0.21419394537313646\n",
      "Batch 10250:0.23791716992855072,0.21553134957794703\n",
      "Batch 10300:0.18746180832386017,0.21716193222487412\n",
      "Batch 10350:0.32769423723220825,0.21999840041081775\n",
      "Batch 10400:0.23574091494083405,0.21954666997653496\n",
      "Batch 10450:0.10186687856912613,0.21609920822354664\n",
      "Batch 10500:0.09689061343669891,0.21348700857758054\n",
      "Batch 10550:0.18735343217849731,0.20635782194454322\n",
      "Samples 0\n",
      "Samples 6400\n",
      "Samples 12800\n",
      "Samples 19200\n",
      "Samples 25600\n",
      "Samples 32000\n",
      "Samples 38400\n",
      "Samples 44800\n",
      "Samples 51200\n"
     ]
    }
   ],
   "source": [
    "start_epoch = 0\n",
    "number_epochs = 6\n",
    "smoothing_constant = .01\n",
    "for e in range(start_epoch, number_epochs):\n",
    "    for i, (review, label) in enumerate(train_dataloader):\n",
    "        review = review.as_in_context(ctx)\n",
    "        label = label.as_in_context(ctx)\n",
    "        with autograd.record():\n",
    "            output = net(review)\n",
    "            loss = softmax_cross_entropy(output, label)\n",
    "        loss.backward()\n",
    "        trainer.step(review.shape[0])\n",
    "        \n",
    "        # moving average of the loss\n",
    "        curr_loss = nd.mean(loss).asscalar()\n",
    "        moving_loss = (curr_loss if (i == 0) \n",
    "                       else (1 - smoothing_constant) * moving_loss + (smoothing_constant) * curr_loss)\n",
    "\n",
    "        if (i%50 == 0):\n",
    "            nd.waitall()\n",
    "            print('Batch {}:{},{}'.format(i,curr_loss,moving_loss))\n",
    "\n",
    "    test_accuracy = evaluate_accuracy(test_dataloader, net)\n",
    "    #Save the model using the gluon params format\n",
    "    net.save_params('crepe_epoch_{}_test_acc_{}.params'.format(e,int(test_accuracy*10000)/100))\n",
    "    print(\"Epoch %s. Loss: %s, Test_acc %s\" % (e, moving_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Test with example reveiw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "review_title = \"Good stuff\"\n",
    "review = \"This album is definitely better than the previous one\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(review_title)\n",
    "print(review + '\\n')\n",
    "encoded = nd.array([encode(review + \" | \" + review_title)], ctx=ctx)\n",
    "output = net(encoded)\n",
    "softmax = nd.exp(output) / nd.sum(nd.exp(output))[0]\n",
    "predicted = categories[np.argmax(output[0].asnumpy())]\n",
    "print('Predicted: {}\\n'.format(predicted))\n",
    "for i, val in enumerate(categories):\n",
    "    print(val, float(int(softmax[0][i].asnumpy()*1000)/10), '%')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
